{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Dataset import lerCSV,lerXLSX\n",
    "import warnings\n",
    "import sys \n",
    "import numpy as np\n",
    "import pickle\n",
    "import theanets\n",
    "from sklearn import preprocessing\n",
    "from random import shuffle\n",
    "from sklearn.metrics import precision_score,recall_score,log_loss\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import math\n",
    "from roc import RocAucScoreOp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")   \n",
    "matrix = lerXLSX(\"Banco de Dados - Infarto treinoTeste.xlsx\",training=True,agrupamento=False)\n",
    "def sigmoid(x):\n",
    "  x = (x - 0.5) *  10\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "lista = list(range(0,len(matrix))) \n",
    "shuffle(lista)\n",
    "a = np.asarray(lista) % k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "matrixProcessed = min_max_scaler.fit_transform(matrix[:,:3])\n",
    "#matrixProcessed = preprocessing.normalize(matrix[:,:3], norm='l2')\n",
    "#matrixProcessed = np.array([[matrixProcessed[y,0],matrixProcessed[y,1],matrixProcessed[y,2],matrixProcessed[y,3]]  for y in range(0,len(matrix[:,0]))])\n",
    "matrixProcessed = matrixProcessed = np.array([[matrixProcessed[y,0],sigmoid(matrixProcessed[y,1]),matrixProcessed[y,2]]  for y in range(0,len(matrix[:,0]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def specificity(outputs,predicts):\n",
    "    neg = np.sum([output == 0 for output in outputs])\n",
    "    tn = np.sum([predicts[x] == outputs[x] and outputs[x] == 0 for x in range(len(predicts))])\n",
    "    return tn / neg\n",
    "\n",
    "def KFold(matrix,metric):\n",
    "    k = 8\n",
    "    \n",
    "    limit = 3\n",
    "    \n",
    "    \n",
    "    lista = list(range(1,len(matrix))) \n",
    "    shuffle(lista)\n",
    "    a = np.asarray(lista) % k   \n",
    "    \n",
    "    scores = np.zeros(k)\n",
    "    scoresT = np.zeros(k)\n",
    "    recall = np.zeros(k)\n",
    "    precision = np.zeros(k)\n",
    "    average_precision = np.zeros(k)\n",
    "    \n",
    "    for fold in range(0,k):\n",
    "        treinoIndex = np.where(a != fold)[0]\n",
    "        testeIndex =  np.where(a == fold)[0]        \n",
    "        \n",
    "        inputs = np.array([[matrix[y,0],matrix[y,1],matrix[y,2]]  for y in treinoIndex])\n",
    "        weights = np.array([int(matrix[y,3] == 1)*0+1 for y in treinoIndex],dtype=\"int32\")        \n",
    "        outputs = np.array([int(matrix[y,3] == 1) for y in treinoIndex],dtype=\"int32\")\n",
    "            \n",
    "        model = theanets.Classifier(metric[1],loss='CrossEntropy',weighted=True)  \n",
    "        saidaT = model.train([inputs, outputs,weights],algo='sgd',learning_rate=0.01,momentum=0.9)       \n",
    "        \n",
    "        testOutputs = [matrix[y,3] for y in testeIndex] \n",
    "        testInputs = np.array([matrix[y,:3]  for y in testeIndex])   \n",
    "        predicts = model.predict(testInputs)\n",
    "        predictsProbas = model.predict_proba(testInputs)\n",
    "        scores[fold] = log_loss(testOutputs, predictsProbas)\n",
    "        scoresT[fold] = saidaT[\"err\"] \n",
    "        recall[fold] = recall_score(testOutputs, predicts)\n",
    "        precision[fold] = specificity(testOutputs, predicts)        \n",
    "        \n",
    "    \n",
    "    print(\"Final:\"+ metric[0] + \" = Error:%2.2e[+/- %2.2e]\"%(np.mean(scores),np.std(scores)))\n",
    "    print(\"Final:\"+ metric[0] + \" = Sensitive:%2.2e[+/- %2.2e]\"%(np.mean(recall),np.std(recall)))\n",
    "    print(\"Final:\"+ metric[0] + \" = specificity:%2.2e[+/- %2.2e]\"%(np.mean(precision),np.std(precision)))       \n",
    "    return np.mean(recall), np.mean(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputOutput = np.array([np.concatenate((matrixProcessed[x,:3],[matrix[x,3] == 1]),axis=0) for x in range(0,len(matrix[:,3]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final:neural network (3,2) = Error:5.02e-01[+/- 3.92e-02]\n",
      "Final:neural network (3,2) = Sensitive:5.61e-01[+/- 7.67e-02]\n",
      "Final:neural network (3,2) = specificity:8.72e-01[+/- 4.69e-02]\n",
      "Final:neural network (3,1 tanh,2) = Error:5.05e-01[+/- 6.07e-02]\n",
      "Final:neural network (3,1 tanh,2) = Sensitive:5.90e-01[+/- 9.32e-02]\n",
      "Final:neural network (3,1 tanh,2) = specificity:8.53e-01[+/- 4.11e-02]\n",
      "Final:neural network (3,2 tanh,2) = Error:5.00e-01[+/- 4.43e-02]\n",
      "Final:neural network (3,2 tanh,2) = Sensitive:6.23e-01[+/- 5.43e-02]\n",
      "Final:neural network (3,2 tanh,2) = specificity:8.29e-01[+/- 5.18e-02]\n",
      "Final:neural network (3,3 tanh,2) = Error:5.02e-01[+/- 5.70e-02]\n",
      "Final:neural network (3,3 tanh,2) = Sensitive:6.07e-01[+/- 8.82e-02]\n",
      "Final:neural network (3,3 tanh,2) = specificity:8.17e-01[+/- 2.97e-02]\n"
     ]
    }
   ],
   "source": [
    "metrics = [   [\"neural network (3,2)\",[3, 2]],[\"neural network (3,1 tanh,2)\",[3, (1,\"tanh\"), 2]],[\"neural network (3,2 tanh,2)\",[3, (2, 'tanh'), 2]],[\"neural network (3,3 tanh,2)\",[3, (3, 'tanh'), 2]],[\"neural network (3,5 tanh,2)\",[3, (5, 'tanh'), 2]], [\"neural network (3,7 tanh,2)\",[3, (7, 'tanh'), 2]], [\"neural network (3,10 tanh,2)\",[3, (10, 'tanh'), 2]], [\"neural network (3,15 tanh,2)\",[3, (15, 'tanh'), 2]], [\"neural network (3,5 tanh,5 tanh,2)\",[3,(5, 'tanh'), (5, 'tanh'), 2]], [\"neural network (3,10 tanh,5 tanh,2)\",[3,(10, 'tanh'), (10, 'tanh'), 2]]]\n",
    "saida = np.array([ KFold(inputOutput, metric=metric) for metric in metrics])\n",
    "np.savetxt('3features.csv', saida, delimiter=',')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
